{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x1GI7Fo8Y7x"
      },
      "source": [
        "# **Custom Knowledge ChatGPT with LangChain - Chat with PDFs**\n",
        "\n",
        "**By Liam Ottley:**  [YouTube](https://youtube.com/@LiamOttley)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "0.   Installs, Imports and API Keys\n",
        "1.   Loading PDFs and chunking with LangChain\n",
        "2.   Embedding text and storing embeddings\n",
        "3.   Creating retrieval function\n",
        "4.   Creating chatbot with chat memory (OPTIONAL)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q24Y-g6h-Bg0"
      },
      "source": [
        "# 0. Installs, Imports and API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gk2J2sYYjTkM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting textract\n",
            "  Using cached textract-1.6.5-py3-none-any.whl (23 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.0.304-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: IPython in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (8.15.0)\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting argcomplete~=1.10.0\n",
            "  Using cached argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting beautifulsoup4~=4.8.0\n",
            "  Using cached beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "Collecting chardet==3.*\n",
            "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "Collecting docx2txt~=0.8\n",
            "  Using cached docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting extract-msg<=0.29.*\n",
            "  Using cached extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "Collecting pdfminer.six==20191110\n",
            "  Using cached pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "Collecting python-pptx~=0.6.18\n",
            "  Using cached python_pptx-0.6.22-py3-none-any.whl (471 kB)\n",
            "Collecting six~=1.12.0\n",
            "  Using cached six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting SpeechRecognition~=3.8.1\n",
            "  Using cached SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "Collecting xlrd~=1.2.0\n",
            "  Using cached xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "Collecting pycryptodome\n",
            "  Using cached pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Collecting sortedcontainers\n",
            "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.17\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 2)) (23.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2023.8.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.4/782.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1\n",
            "  Downloading safetensors-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>=4.27\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting SQLAlchemy<3,>=1.4\n",
            "  Downloading SQLAlchemy-2.0.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3\n",
            "  Downloading aiohttp-3.8.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hCollecting anyio<4.0\n",
            "  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.38\n",
            "  Downloading langsmith-0.0.41-py3-none-any.whl (39 kB)\n",
            "Collecting numexpr<3.0.0,>=2.8.4\n",
            "  Downloading numexpr-2.8.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<3,>=1\n",
            "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: backcall in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 4)) (0.19.0)\n",
            "Requirement already satisfied: matplotlib-inline in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 4)) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 4)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 4)) (3.0.39)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 4)) (2.16.1)\n",
            "Requirement already satisfied: stack-data in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: traitlets>=5 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 4)) (5.10.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 4)) (4.8.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 5)) (0.1.4)\n",
            "Collecting widgetsnbextension~=4.0.9\n",
            "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-widgets~=3.0.9\n",
            "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting attrs>=17.3.0\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4.0,>=2.0\n",
            "  Downloading charset_normalizer-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m450.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.8/282.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.4.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.5/250.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting idna>=2.8\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting soupsieve>=1.2\n",
            "  Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0\n",
            "  Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting imapclient==2.1.0\n",
            "  Using cached IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "Collecting olefile>=0.46\n",
            "  Using cached olefile-0.46.zip (112 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tzlocal>=2.1\n",
            "  Downloading tzlocal-5.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting compressed-rtf>=1.0.6\n",
            "  Using cached compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting ebcdic>=1.1.1\n",
            "  Using cached ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=3.7.4.3\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from jedi>=0.16->IPython->-r requirements.txt (line 4)) (0.8.3)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from pexpect>4.3->IPython->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->-r requirements.txt (line 4)) (0.2.6)\n",
            "Collecting annotated-types>=0.4.0\n",
            "  Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
            "Collecting pydantic-core==2.10.1\n",
            "  Downloading pydantic_core-2.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting lxml>=3.1.0\n",
            "  Downloading lxml-4.9.3-cp311-cp311-manylinux_2_28_x86_64.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<=9.5.0,>=3.3.2\n",
            "  Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting XlsxWriter>=0.5.7\n",
            "  Downloading XlsxWriter-3.1.5-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.5-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting greenlet!=0.4.17\n",
            "  Downloading greenlet-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.8/618.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: executing>=1.2.0 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from stack-data->IPython->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from stack-data->IPython->-r requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: pure-eval in /home/mo/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages (from stack-data->IPython->-r requirements.txt (line 4)) (0.2.2)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tokenizers, SpeechRecognition, sortedcontainers, safetensors, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, XlsxWriter, xlrd, widgetsnbextension, urllib3, tzlocal, typing-extensions, tqdm, tenacity, soupsieve, sniffio, six, regex, pyyaml, pycryptodome, Pillow, olefile, numpy, mypy-extensions, multidict, marshmallow, lxml, jupyterlab-widgets, jsonpointer, idna, greenlet, fsspec, frozenlist, filelock, charset-normalizer, certifi, attrs, async-timeout, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, python-pptx, pydantic-core, pdfminer.six, numexpr, jsonpatch, imapclient, beautifulsoup4, anyio, aiosignal, pydantic, huggingface-hub, extract-msg, dataclasses-json, aiohttp, transformers, textract, langsmith, langchain, ipywidgets\n",
            "\u001b[33m  DEPRECATION: docx2txt is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py install for docx2txt ... \u001b[?25ldone\n",
            "\u001b[?25h\u001b[33m  DEPRECATION: compressed-rtf is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py install for compressed-rtf ... \u001b[?25ldone\n",
            "\u001b[?25h  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "\u001b[33m  DEPRECATION: olefile is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py install for olefile ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed Pillow-9.5.0 SQLAlchemy-2.0.21 SpeechRecognition-3.8.1 XlsxWriter-3.1.5 aiohttp-3.8.5 aiosignal-1.3.1 annotated-types-0.5.0 anyio-3.7.1 argcomplete-1.10.3 async-timeout-4.0.3 attrs-23.1.0 beautifulsoup4-4.8.2 certifi-2023.7.22 chardet-3.0.4 charset-normalizer-3.2.0 compressed-rtf-1.0.6 dataclasses-json-0.6.1 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 filelock-3.12.4 frozenlist-1.4.0 fsspec-2023.9.2 greenlet-2.0.2 huggingface-hub-0.17.3 idna-3.4 imapclient-2.1.0 ipywidgets-8.1.1 jsonpatch-1.33 jsonpointer-2.4 jupyterlab-widgets-3.0.9 langchain-0.0.304 langsmith-0.0.41 lxml-4.9.3 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 numexpr-2.8.7 numpy-1.26.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.19.0 pydantic-2.4.2 pydantic-core-2.10.1 python-pptx-0.6.22 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 safetensors-0.3.3 six-1.12.0 sniffio-1.3.0 sortedcontainers-2.4.0 soupsieve-2.5 tenacity-8.2.3 textract-1.6.5 tokenizers-0.13.3 tqdm-4.66.1 transformers-4.33.3 typing-extensions-4.8.0 typing-inspect-0.9.0 tzlocal-5.0.1 urllib3-2.0.5 widgetsnbextension-4.0.9 xlrd-1.2.0 yarl-1.9.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l-uszlwN641q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import GPT2TokenizerFast\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "import textract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "E2Buv5Y0uFr8"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "# openai.api_key  = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLULMPXa-Hu8"
      },
      "source": [
        "# 1. Loading PDFs and chunking with LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH546j3nkFwX",
        "outputId": "fc5bb7da-59ac-49d4-8ac5-2cfe73483225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='MIDWEST STUDIES IN PHILOSOPHY, XVIII (1993) \\nCould There Be a Science of Economics? \\nJOHN DUPa \\nuch scientific thinking and thinking about science involves the assump- M tion that there is a deep and pervasive order to the world that it is the \\nbusiness of science to disclose. A paradigmatic statement of such a view can be \\nfound in a widely discussed paper by a prominent economist, Milton Friedman \\n(a paper which will be discussed in more detail shortly): \\nA fundamental hypothesis of science is that appearances are deceptive and \\nthat there is a way of looking at or interpreting or organizing the evidence \\nthat will reveal superficially disconnected and diverse phenomena to be \\nmanifestations of a more fundamental and relatively simple structure. \\n(195311984. 231) \\nOn the other hand, the person sometimes described as the father of modern \\nscience, Francis Bacon, wrote: \\nThe human understanding is of its own nature prone to suppose the \\nexistence of more order and regularity in the world than it finds. And \\nthough there be many things in nature which are singular and unmatched, \\nyet it devises for them conjugates and relatives which do not exist. \\n( 1620/1960, 50) \\nI myself find the empiricism of Bacon’s position much more attractive than \\nFriedman’s rationalism. Assumptions of the kind Friedman’s remark illustrates \\nlead naturally, almost inevitably, to philosophical doctrines such as reduction- \\nism (of various kinds) and determinism. In a recent book (Duprk 1993) I have \\nargued at length against various doctrines of these kinds and, more generally, \\nagainst the assumption of underlying metaphysical order with which they are \\ninextricably connected. In the concluding chapters of that book I suggested \\nthat more modest and defensible views of the prevalence of order in the world \\nwould have important consequences for our general understanding of science, \\n363' metadata={'source': './Dupre_economy_as_science.pdf', 'page': 0}\n"
          ]
        }
      ],
      "source": [
        "# You MUST add your PDF to local files in this notebook (folder icon on left hand side of screen)\n",
        "pdf_path = \"./Dupre_economy_as_science.pdf\"\n",
        "\n",
        "# Simple method - Split by pages\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "pages = loader.load_and_split()\n",
        "print(pages[0])\n",
        "\n",
        "# SKIP TO STEP 2 IF YOU'RE USING THIS METHOD\n",
        "chunks = pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iADY2CXNlNq9"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages/textract/parsers/utils.py:87\u001b[0m, in \u001b[0;36mShellParser.run\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     pipe \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(\n\u001b[1;32m     88\u001b[0m         args,\n\u001b[1;32m     89\u001b[0m         stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE, stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     91\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/subprocess.py:1024\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m   1022\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m-> 1024\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m   1025\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m   1026\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m   1027\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m   1028\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m   1029\u001b[0m                         errread, errwrite,\n\u001b[1;32m   1030\u001b[0m                         restore_signals,\n\u001b[1;32m   1031\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m   1032\u001b[0m                         start_new_session, process_group)\n\u001b[1;32m   1033\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m   1034\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1917\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1918\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pdftotext'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mShellError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages/textract/parsers/pdf_parser.py:21\u001b[0m, in \u001b[0;36mParser.extract\u001b[0;34m(self, filename, method, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_pdftotext(filename, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     22\u001b[0m \u001b[39mexcept\u001b[39;00m ShellError \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m     23\u001b[0m     \u001b[39m# If pdftotext isn't installed and the pdftotext method\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39m# wasn't specified, then gracefully fallback to using\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[39m# pdfminer instead.\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages/textract/parsers/pdf_parser.py:44\u001b[0m, in \u001b[0;36mParser.extract_pdftotext\u001b[0;34m(self, filename, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m     args \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mpdftotext\u001b[39m\u001b[39m'\u001b[39m, filename, \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 44\u001b[0m stdout, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(args)\n\u001b[1;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m stdout\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages/textract/parsers/utils.py:95\u001b[0m, in \u001b[0;36mShellParser.run\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mENOENT:\n\u001b[1;32m     93\u001b[0m     \u001b[39m# File not found.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[39m# This is equivalent to getting exitcode 127 from sh\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mShellError(\n\u001b[1;32m     96\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(args), \u001b[39m127\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39mraise\u001b[39;00m \u001b[39m#Reraise the last exception unmodified\u001b[39;00m\n",
            "\u001b[0;31mShellError\u001b[0m: The command `pdftotext ./Dupre_economy_as_science.pdf -` failed because the executable\n`pdftotext` is not installed on your system. Please make\nsure the appropriate dependencies are installed before using\ntextract:\n\n    http://textract.readthedocs.org/en/latest/installation.html\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Advanced method - Split by chunk\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Step 1: Convert PDF to text\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m doc \u001b[39m=\u001b[39m textract\u001b[39m.\u001b[39;49mprocess(pdf_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Step 2: Save to .txt and reopen (helps prevent issues)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(pdf_path, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages/textract/parsers/__init__.py:79\u001b[0m, in \u001b[0;36mprocess\u001b[0;34m(filename, input_encoding, output_encoding, extension, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m# do the extraction\u001b[39;00m\n\u001b[1;32m     78\u001b[0m parser \u001b[39m=\u001b[39m filetype_module\u001b[39m.\u001b[39mParser()\n\u001b[0;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mprocess(filename, input_encoding, output_encoding, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages/textract/parsers/utils.py:46\u001b[0m, in \u001b[0;36mBaseParser.process\u001b[0;34m(self, filename, input_encoding, output_encoding, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Process ``filename`` and encode byte-string with ``encoding``. This\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mmethod is called by :func:`textract.parsers.process` and wraps\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39mthe :meth:`.BaseParser.extract` method in `a delicious unicode\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39msandwich <http://nedbatchelder.com/text/unipain.html>`_.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# make a \"unicode sandwich\" to handle dealing with unknown\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m# input byte strings and converting them to a predictable\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m# output encoding\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m# http://nedbatchelder.com/text/unipain/unipain.html#35\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m byte_string \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract(filename, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     47\u001b[0m unicode_string \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(byte_string, input_encoding)\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode(unicode_string, output_encoding)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages/textract/parsers/pdf_parser.py:27\u001b[0m, in \u001b[0;36mParser.extract\u001b[0;34m(self, filename, method, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mexcept\u001b[39;00m ShellError \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m     23\u001b[0m     \u001b[39m# If pdftotext isn't installed and the pdftotext method\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39m# wasn't specified, then gracefully fallback to using\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[39m# pdfminer instead.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m ex\u001b[39m.\u001b[39mis_not_installed():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_pdfminer(filename, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     28\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[39mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages/textract/parsers/pdf_parser.py:54\u001b[0m, in \u001b[0;36mParser.extract_pdfminer\u001b[0;34m(self, filename, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m pdf2txt_path \u001b[39m=\u001b[39m find_executable(\u001b[39m'\u001b[39m\u001b[39mpdf2txt.py\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     stdout, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun([\u001b[39m'\u001b[39;49m\u001b[39mpdf2txt.py\u001b[39;49m\u001b[39m'\u001b[39;49m, filename])\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/pdfchatenv/lib/python3.11/site-packages/textract/parsers/utils.py:102\u001b[0m, in \u001b[0;36mShellParser.run\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39melse\u001b[39;00m: \u001b[39mraise\u001b[39;00m \u001b[39m#Reraise the last exception unmodified\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m# pipe.wait() ends up hanging on large files. using\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m# pipe.communicate appears to avoid this issue\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m stdout, stderr \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39;49mcommunicate()\n\u001b[1;32m    104\u001b[0m \u001b[39m# if pipe is busted, raise an error (unlike Fabric)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m pipe\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/subprocess.py:1207\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1207\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[1;32m   1208\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1209\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/subprocess.py:2075\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2068\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2069\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2070\u001b[0m                         skip_check_and_raise\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   2071\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(  \u001b[39m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2072\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2073\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfailed to raise TimeoutExpired.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 2075\u001b[0m ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m   2076\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2078\u001b[0m \u001b[39m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2079\u001b[0m \u001b[39m# objects; they are no longer using C stdio!\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selector\u001b[39m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Advanced method - Split by chunk\n",
        "\n",
        "# Step 1: Convert PDF to text\n",
        "doc = textract.process(pdf_path)\n",
        "\n",
        "# Step 2: Save to .txt and reopen (helps prevent issues)\n",
        "with open(pdf_path, 'w') as f:\n",
        "    f.write(doc.decode('utf-8'))\n",
        "\n",
        "with open(pdf_path, 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Step 3: Create function to count tokens\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "# Step 4: Split text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 512,\n",
        "    chunk_overlap  = 24,\n",
        "    length_function = count_tokens,\n",
        ")\n",
        "\n",
        "chunks = text_splitter.create_documents([text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ_gDkwep4q7",
        "outputId": "ef5323ce-2ea2-4a44-f8cd-31f93d066112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "langchain.schema.document.Document"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Result is many LangChain 'Documents' around 500 tokens or less (Recursive splitter sometimes allows more tokens to retain context)\n",
        "type(chunks[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "fK31bxDOpz1l",
        "outputId": "ad765c54-d21b-43ad-ee6a-1efe0c3963ca"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'count_tokens' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Quick data visualization to ensure chunking was successful\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Create a list of token counts\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m token_counts \u001b[39m=\u001b[39m [count_tokens(chunk\u001b[39m.\u001b[39;49mpage_content) \u001b[39mfor\u001b[39;49;00m chunk \u001b[39min\u001b[39;49;00m chunks]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Create a DataFrame from the token counts\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mToken Count\u001b[39m\u001b[39m'\u001b[39m: token_counts})\n",
            "\u001b[1;32m/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Quick data visualization to ensure chunking was successful\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Create a list of token counts\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m token_counts \u001b[39m=\u001b[39m [count_tokens(chunk\u001b[39m.\u001b[39mpage_content) \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunks]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Create a DataFrame from the token counts\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mo/code/mooorice/pdfchatter/pdf_chatter_0.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mToken Count\u001b[39m\u001b[39m'\u001b[39m: token_counts})\n",
            "\u001b[0;31mNameError\u001b[0m: name 'count_tokens' is not defined"
          ]
        }
      ],
      "source": [
        "# Quick data visualization to ensure chunking was successful\n",
        "\n",
        "# Create a list of token counts\n",
        "token_counts = [count_tokens(chunk.page_content) for chunk in chunks]\n",
        "\n",
        "# Create a DataFrame from the token counts\n",
        "df = pd.DataFrame({'Token Count': token_counts})\n",
        "\n",
        "# Create a histogram of the token count distribution\n",
        "df.hist(bins=40, )\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IlznUDK-i2m"
      },
      "source": [
        "# 2. Embed text and store embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "92ObhTAKnZzQ"
      },
      "outputs": [],
      "source": [
        "# Get embedding model\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create vector database\n",
        "db = FAISS.from_documents(pages, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LPwdGDP-nPO"
      },
      "source": [
        "# 3. Setup retrieval function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWP92zGg5Nb_",
        "outputId": "6c698c0c-d895-4aac-ff7c-15c557435a9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='366 JOHN DUPRE \\nit is striking how little he says in this article to justify complacence about \\nthe predictive powers of economics. Friedman compares, for example, the \\nhypothesis that businessmen act as if they aimed to maximize profits with \\nthe hypothesis that expert billiard players act as if they were able to make \\nall the appropriate mathematical calculations of the trajectory of a billiard ball. \\nThe value of this latter hypothesis is sufficiently demonstrated by the successful \\nshots of the expert billiard player, and the psychology of neither the billiard- \\nplayer nor the businessman is of any relevance to the evaluation of either \\nhypothesis. But remarkably, rather than offer any empirical evidence that, just \\nas expert billiard players generally make their shots, businessmen, whatever \\nthey may be intending, do in fact maximize profits, Friedman offers nothing but \\na broken-backed a priori argument for this conclusion. “[Ulnless the behavior \\nof businessmen in some way or other approximated behavior consistent with \\nthe maximization of returns,” he writes, “it seems unlikely that they would \\nremain in business for long” (223). But the implicit argument here has no \\nforce unless it is assumed that the competitors of the non-profit-maximizing \\nbusinessman are profit maximizers, which is blatantly question-begging. If \\nno businesses, or very few businesses, are profit-maximizers, there may be \\nvery little tendency for non-profit-maximizing firms to go out of business. \\nPerhaps survival in business is largely a matter of luck, or of access to corrupt \\ngovernment officials. Distinguishing between these and many other possible \\nhypotheses would require empirical evidence of a kind that Friedman neither \\noffers nor, apparently, sees the need for. \\nAnother example Friedman offers is the hypothesis that a sudden increase \\nin the money supply will produce a substantial increase in prices (216). \\nAlthough the “evidence is dramatic” for this hypothesis Friedman admits \\nregretfully that the issue remains highly contentious, an observation that might \\nreasonably lead the external observer of economics to wonder whether this \\nparadigm of empirical support could be quite that dramatic. It appears that \\nin the end Friedman wants to appeal not to ‘‘my textbook list of instances \\nin which the hypothesis has failed to be contradicted” (224), but rather to \\n“experience from countless applications of the hypothesis to specific problems \\nand the repeated failure of its implications to be contradicted. This evidence \\nis extremely hard to document; it is scattered in numerous memorandums, \\narticles, and monographs. . . ’* (223-24). In contemporary philosophy of sci- \\nence, where the constant apparent confirmation of the basic assumptions of \\na research program, or a paradigm during normal science, etc., has become \\na commonplace, this appeal is unlikely to impress. Friedman’s paradigmatic \\nthough pre-Kuhnian description of a Kuhnian paradigm becomes even more \\nstriking when we read that the ability to apply economic models in the right way \\nrequires considerable professional judgment. This “is something that cannot be \\ntaught; it can be learned, but only by experience and exposure in the ‘right’ \\nscientific atmosphere, not by rote. It is at this point that the ‘amateur’ is \\nseparated from the ‘professional’ in all sciences and the thin line is drawn \\nwhich distinguishes the ‘crackpot’ from the scientist” (226). Very likely, this', metadata={'source': './Dupre_economy_as_science.pdf', 'page': 3})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check similarity search is working\n",
        "query = \"does dupre agree with friedman?\"\n",
        "docs = db.similarity_search(query)\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1Kv_sM8G5qAo",
        "outputId": "00171d21-312a-455e-b361-2306c6dc4b75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" I don't know.\""
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create QA chain to integrate similarity search with user queries (answer query from knowledge base)\n",
        "\n",
        "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "\n",
        "query = \"Who created transformers?\"\n",
        "docs = db.similarity_search(query)\n",
        "\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_nH1qoL-w--"
      },
      "source": [
        "# 5. Create chatbot with chat memory (OPTIONAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "evF7_Dyhtcaf"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Create conversation chain that uses our vectordb as retriver, this also allows for chat history management\n",
        "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.1), db.as_retriever())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "bf4eac20add04b57a1af538f80f2980c",
            "867b911c7aac4dc7bdf6923d3a464c1e",
            "a32ffe2bd6974b6eaa8a3081a8c1816b",
            "7a260cc663614805b499690a5a2cb5be",
            "93571528b372443592d502bebd336ca0",
            "94ce74af3988415ca43a5d23accce7ca",
            "c64aac8fce884e45a012006e2dc20402",
            "a7231aad9ce941bbbe2c5916fbb502d3",
            "ccae43d897aa4185938744e0e68c8eca",
            "a6fc81eb00c1487f8bcf296d3f1f09ba",
            "4b2f4c5464294d38af0c4b502c3aa838",
            "0548b5525848403498cfcad4fed553d3",
            "5b78945e3add476b94fdbfe8eb632471",
            "ca43dc21b81546faa8cc778937b073dc",
            "61c8dc3391e148e8a2467caff97392a1",
            "9a4f5a05dbb344e897b6be9b2f7b4ad0",
            "322af3a06d1646f794f69dea2b799fcb",
            "5540d70ffbeb4126ae94aed1ebaa95aa",
            "22308835851f4231a9f4787a718d2e5c",
            "14005694bb3d4bfbabd3944d8d49fa1c",
            "d2125f0742944b1f95996928c87a1a80"
          ]
        },
        "id": "-pHw5siewPNt",
        "outputId": "e3fb32a5-84fc-47a1-84cd-df0c763f7720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Transformers chatbot! Type 'exit' to stop.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1294/3589111581.py:20: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
            "  input_box.on_submit(on_submit)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "288ea7c04e7c4d41aa47425a896d0a08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Text(value='', placeholder='Please enter your question:')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cc74c3f1fa64b52a9d66a4d428ab4b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HTML(value='<b>User:</b> summarize the given text')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a95de8307234ef097bd48dbec608edc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b>  The text discusses the possibility of economics being a…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6ad2c3d1e5b4a6290a7fc6483a9250d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HTML(value='<b>User:</b> give me the main arguments for his claims')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c8579f3a19948079c6e5ad384e7d766",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b>  The author argues that economics provides an example of…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c957351027e4e61974d726b5fc6a40d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HTML(value='<b>User:</b> what, according to the author, would be genuinely scientific?')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ab533577e6840f1a8367f7c6e775f26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b>  The author considers the identification of causal influ…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb11ef6198684c8e94c7be3a852e86db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HTML(value='<b>User:</b> how would the author define science?')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e2f36128da74428a44d26bcd9d47854",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HTML(value='<b><font color=\"blue\">Chatbot:</font></b>  The author\\'s definition of science is that it involves…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "chat_history = []\n",
        "\n",
        "def on_submit(_):\n",
        "    query = input_box.value\n",
        "    input_box.value = \"\"\n",
        "\n",
        "    if query.lower() == 'exit':\n",
        "        print(\"Thank you for using the State of the Union chatbot!\")\n",
        "        return\n",
        "\n",
        "    result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "    chat_history.append((query, result['answer']))\n",
        "\n",
        "    display(widgets.HTML(f'<b>User:</b> {query}'))\n",
        "    display(widgets.HTML(f'<b><font color=\"blue\">Chatbot:</font></b> {result[\"answer\"]}'))\n",
        "\n",
        "print(\"Welcome to the Transformers chatbot! Type 'exit' to stop.\")\n",
        "\n",
        "input_box = widgets.Text(placeholder='Please enter your question:')\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "display(input_box)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "import gradio as gr\n",
        "\n",
        "def random_response(message, history):\n",
        "    return random.choice([\"Yes\", \"No\"])\n",
        "\n",
        "demo = gr.ChatInterface(random_response)\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0548b5525848403498cfcad4fed553d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14005694bb3d4bfbabd3944d8d49fa1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22308835851f4231a9f4787a718d2e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14005694bb3d4bfbabd3944d8d49fa1c",
            "placeholder": "​",
            "style": "IPY_MODEL_d2125f0742944b1f95996928c87a1a80",
            "value": "<b><font color=\"blue\">Chatbot:</font></b>  Yes, I think they were smart."
          }
        },
        "322af3a06d1646f794f69dea2b799fcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2f4c5464294d38af0c4b502c3aa838": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5540d70ffbeb4126ae94aed1ebaa95aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b78945e3add476b94fdbfe8eb632471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca43dc21b81546faa8cc778937b073dc",
            "placeholder": "​",
            "style": "IPY_MODEL_61c8dc3391e148e8a2467caff97392a1",
            "value": "<b><font color=\"blue\">Chatbot:</font></b>  I don't know."
          }
        },
        "61c8dc3391e148e8a2467caff97392a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a260cc663614805b499690a5a2cb5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93571528b372443592d502bebd336ca0",
            "placeholder": "​",
            "style": "IPY_MODEL_94ce74af3988415ca43a5d23accce7ca",
            "value": "<b>User:</b> Who created transformers?"
          }
        },
        "867b911c7aac4dc7bdf6923d3a464c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93571528b372443592d502bebd336ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ce74af3988415ca43a5d23accce7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a4f5a05dbb344e897b6be9b2f7b4ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_322af3a06d1646f794f69dea2b799fcb",
            "placeholder": "​",
            "style": "IPY_MODEL_5540d70ffbeb4126ae94aed1ebaa95aa",
            "value": "<b>User:</b> I think they were"
          }
        },
        "a32ffe2bd6974b6eaa8a3081a8c1816b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6fc81eb00c1487f8bcf296d3f1f09ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2f4c5464294d38af0c4b502c3aa838",
            "placeholder": "​",
            "style": "IPY_MODEL_0548b5525848403498cfcad4fed553d3",
            "value": "<b>User:</b> Were they smart?"
          }
        },
        "a7231aad9ce941bbbe2c5916fbb502d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4eac20add04b57a1af538f80f2980c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_867b911c7aac4dc7bdf6923d3a464c1e",
            "placeholder": "Please enter your question:",
            "style": "IPY_MODEL_a32ffe2bd6974b6eaa8a3081a8c1816b",
            "value": ""
          }
        },
        "c64aac8fce884e45a012006e2dc20402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7231aad9ce941bbbe2c5916fbb502d3",
            "placeholder": "​",
            "style": "IPY_MODEL_ccae43d897aa4185938744e0e68c8eca",
            "value": "<b><font color=\"blue\">Chatbot:</font></b>  Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin created transformers."
          }
        },
        "ca43dc21b81546faa8cc778937b073dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccae43d897aa4185938744e0e68c8eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2125f0742944b1f95996928c87a1a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
